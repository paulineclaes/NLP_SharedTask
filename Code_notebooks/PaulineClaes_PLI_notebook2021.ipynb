{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "round-salon",
   "metadata": {},
   "source": [
    "# NLP Shared Task 2021\n",
    "\n",
    "## Proficiency Level Identification Notebook\n",
    "\n",
    "Pauline Claes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "polyphonic-immune",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paulineclaes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk__word_tokenizer = word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "continental-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "accompanied-prize",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.txt</td>\n",
       "      <td>Some people might think that traveling in a gr...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>high</td>\n",
       "      <td>DT NNS MD VB IN VBG IN DT NN VBN IN DT NN NN V...</td>\n",
       "      <td>some people may think that travel in a group l...</td>\n",
       "      <td>384</td>\n",
       "      <td>16</td>\n",
       "      <td>1940</td>\n",
       "      <td>some that in a by a is a a has its and does no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278.txt</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN NN CC NN IN VBG VBZ RB VBG , _SP NN VBZ JJ ...</td>\n",
       "      <td>ithe importance and popularity of travel be st...</td>\n",
       "      <td>321</td>\n",
       "      <td>13</td>\n",
       "      <td>1645</td>\n",
       "      <td>and of is is in to other and but the how to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348.txt</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>PRP VBZ DT JJ NN , WRB TO VB PRP$ NN . DT NNS ...</td>\n",
       "      <td>-PRON- be an important decision , how to plan ...</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>2022</td>\n",
       "      <td>it is an how to your some to a of and their so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666.txt</td>\n",
       "      <td>Some people believe that young people can enjo...</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "      <td>DT NNS VBP IN JJ NNS MD VB NN JJR IN JJR NN VB...</td>\n",
       "      <td>some people believe that young people can enjo...</td>\n",
       "      <td>347</td>\n",
       "      <td>26</td>\n",
       "      <td>1891</td>\n",
       "      <td>some that can more than from my of the is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733.txt</td>\n",
       "      <td>Travelling is  usually considered as good recr...</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "      <td>NNP VBZ _SP RB VBN IN JJ NN _SP IN JJ NNS , IN...</td>\n",
       "      <td>Travelling be   usually consider as good recre...</td>\n",
       "      <td>349</td>\n",
       "      <td>13</td>\n",
       "      <td>1862</td>\n",
       "      <td>is as by as for and it is to have some and a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                               text Language  \\\n",
       "0   88.txt  Some people might think that traveling in a gr...      KOR   \n",
       "1  278.txt  IThe importance and popularity of travelling i...      DEU   \n",
       "2  348.txt  It is an important decision, how to plan your ...      TUR   \n",
       "3  666.txt  Some people believe that young people can enjo...      ZHO   \n",
       "4  733.txt  Travelling is  usually considered as good recr...      TEL   \n",
       "\n",
       "  Proficiency                                           pos_tags  \\\n",
       "0        high  DT NNS MD VB IN VBG IN DT NN VBN IN DT NN NN V...   \n",
       "1      medium  IN NN CC NN IN VBG VBZ RB VBG , _SP NN VBZ JJ ...   \n",
       "2        high  PRP VBZ DT JJ NN , WRB TO VB PRP$ NN . DT NNS ...   \n",
       "3      medium  DT NNS VBP IN JJ NNS MD VB NN JJR IN JJR NN VB...   \n",
       "4      medium  NNP VBZ _SP RB VBN IN JJ NN _SP IN JJ NNS , IN...   \n",
       "\n",
       "                                          lemma_text  n_words  n_sentences  \\\n",
       "0  some people may think that travel in a group l...      384           16   \n",
       "1  ithe importance and popularity of travel be st...      321           13   \n",
       "2  -PRON- be an important decision , how to plan ...      360           15   \n",
       "3  some people believe that young people can enjo...      347           26   \n",
       "4  Travelling be   usually consider as good recre...      349           13   \n",
       "\n",
       "   doc_length                                         stop_words  \n",
       "0        1940  some that in a by a is a a has its and does no...  \n",
       "1        1645  and of is is in to other and but the how to do...  \n",
       "2        2022  it is an how to your some to a of and their so...  \n",
       "3        1891  some that can more than from my of the is the ...  \n",
       "4        1862  is as by as for and it is to have some and a w...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "critical-variation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    5964\n",
       "high      3835\n",
       "low       1201\n",
       "Name: Proficiency, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Proficiency.value_counts() # unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "democratic-swaziland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '(Target) Classes of Proficiency level')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['Proficiency'].value_counts().plot(kind = \"bar\")\n",
    "plt.title(\"Class distribution of Proficiency levels in TOEFL11 dataset\")\n",
    "plt.ylabel(\"Number of instances\")\n",
    "plt.xlabel(\"(Target) Classes of Proficiency level\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "periodic-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text.values\n",
    "y = df.Proficiency.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "relative-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X,\n",
    "                                                  y, \n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-occupation",
   "metadata": {},
   "source": [
    "# 1. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-church",
   "metadata": {},
   "source": [
    "## 1.1. Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "former-michael",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-friendly",
   "metadata": {},
   "source": [
    "### 1.1.1. Dummy Classifier with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enormous-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adult-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "base1 = make_pipeline(cvect, dummy_clf, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "instant-gardening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing countvectorizer, total=   1.8s\n",
      "[Pipeline] ... (step 2 of 2) Processing dummyclassifier, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()),\n",
       "                ('dummyclassifier',\n",
       "                 DummyClassifier(random_state=1, strategy='stratified'))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "moral-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = base1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prompt-customs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3259427657478984\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_dummy, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "spatial-coaching",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.35      0.33      0.34       384\n",
      "         low       0.07      0.08      0.08       120\n",
      "      medium       0.57      0.56      0.56       596\n",
      "\n",
      "    accuracy                           0.43      1100\n",
      "   macro avg       0.33      0.32      0.33      1100\n",
      "weighted avg       0.44      0.43      0.43      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-making",
   "metadata": {},
   "source": [
    "### 1.1.2. Dummy Classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "natural-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "expressed-treasurer",
   "metadata": {},
   "outputs": [],
   "source": [
    "base2 = make_pipeline(tfidf, dummy_clf, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "theoretical-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   1.8s\n",
      "[Pipeline] ... (step 2 of 2) Processing dummyclassifier, total=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('dummyclassifier',\n",
       "                 DummyClassifier(random_state=1, strategy='stratified'))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arranged-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base_2 = base2.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impossible-incident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3259427657478984\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_base_2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fresh-permit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.35      0.33      0.34       384\n",
      "         low       0.07      0.08      0.08       120\n",
      "      medium       0.57      0.56      0.56       596\n",
      "\n",
      "    accuracy                           0.43      1100\n",
      "   macro avg       0.33      0.32      0.33      1100\n",
      "weighted avg       0.44      0.43      0.43      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_base_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specific-reception",
   "metadata": {},
   "source": [
    "## 1.2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-providence",
   "metadata": {},
   "source": [
    "### 1.2.1. SVM and CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "formed-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "strong-multimedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "base3 = make_pipeline(cvect, svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "operational-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer', CountVectorizer()), ('svc', SVC())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ordered-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base3 = base3.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "communist-asbestos",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.717869055926037\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_base3, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "available-drilling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.78      0.63      0.70       384\n",
      "         low       0.80      0.57      0.67       120\n",
      "      medium       0.73      0.86      0.79       596\n",
      "\n",
      "    accuracy                           0.75      1100\n",
      "   macro avg       0.77      0.69      0.72      1100\n",
      "weighted avg       0.75      0.75      0.74      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_base3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-gardening",
   "metadata": {},
   "source": [
    "### 1.2.2. SVM and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "married-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "standard-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "base4 = make_pipeline(tfidf, svm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "verbal-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   1.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing svc, total= 2.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()), ('svc', SVC())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "resident-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base4 = base4.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "backed-cleveland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5898793061354849\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_base4, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "casual-madness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.76      0.65      0.70       384\n",
      "         low       0.85      0.18      0.30       120\n",
      "      medium       0.69      0.86      0.77       596\n",
      "\n",
      "    accuracy                           0.71      1100\n",
      "   macro avg       0.77      0.57      0.59      1100\n",
      "weighted avg       0.73      0.71      0.69      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_base4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-innocent",
   "metadata": {},
   "source": [
    "## 1.3. BERT\n",
    "Please check separate notebook for BERT baseline for Proficiency Level Identification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-detail",
   "metadata": {},
   "source": [
    "# 2. Pipeline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-formula",
   "metadata": {},
   "source": [
    "## 2.1. Pipe1. CountVectorizer and LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "creative-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                        ngram_range=(1,3))\n",
    "linear_svc = LinearSVC(multi_class=\"ovr\", \n",
    "                      class_weight=\"balanced\",\n",
    "                      random_state=1,\n",
    "                      max_iter=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "official-occupation",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(cvect, linear_svc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "gross-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing countvectorizer, total=  33.5s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=  12.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 3),\n",
       "                                 tokenizer=<function word_tokenize at 0x7fecec69eb80>)),\n",
       "                ('linearsvc',\n",
       "                 LinearSVC(class_weight='balanced', max_iter=5000,\n",
       "                           random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "satisfactory-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe1 = pipe1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "subtle-pakistan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.665871432804802\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_pipe1, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "overhead-public",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.72      0.66      0.69       384\n",
      "         low       0.65      0.51      0.57       120\n",
      "      medium       0.71      0.78      0.74       596\n",
      "\n",
      "    accuracy                           0.71      1100\n",
      "   macro avg       0.69      0.65      0.67      1100\n",
      "weighted avg       0.71      0.71      0.70      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-poland",
   "metadata": {},
   "source": [
    "## 2.2. CountVectorizer and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "criminal-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                        ngram_range=(1,3))\n",
    "logreg = LogisticRegression(multi_class=\"ovr\",\n",
    "                            class_weight=\"balanced\", # uses value of y to automatically adjust weights inversely proportional to class frequencies\n",
    "                            max_iter = 5000,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worldwide-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(cvect, logreg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "homeless-google",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing countvectorizer, total=  32.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total= 6.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 3),\n",
       "                                 tokenizer=<function word_tokenize at 0x7fecec69eb80>)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=5000,\n",
       "                                    multi_class='ovr', n_jobs=-1,\n",
       "                                    random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "norman-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe2 = pipe2.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "built-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72212387761445\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_pipe2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "classified-violin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.74      0.74      0.74       384\n",
      "         low       0.67      0.65      0.66       120\n",
      "      medium       0.76      0.77      0.77       596\n",
      "\n",
      "    accuracy                           0.75      1100\n",
      "   macro avg       0.72      0.72      0.72      1100\n",
      "weighted avg       0.75      0.75      0.75      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-button",
   "metadata": {},
   "source": [
    "## 2.3. CountVectorizer and SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "tracked-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                        ngram_range=(1,3))\n",
    "sgd = SGDClassifier(loss=\"log\", \n",
    "                   max_iter=5000, \n",
    "                   n_jobs=-1,\n",
    "                   class_weight=\"balanced\",\n",
    "                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "explicit-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(cvect, sgd, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ordered-aaron",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing countvectorizer, total=  32.8s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   3.3s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('countvectorizer',\n",
       "                 CountVectorizer(ngram_range=(1, 3),\n",
       "                                 tokenizer=<function word_tokenize at 0x7fecec69eb80>)),\n",
       "                ('sgdclassifier',\n",
       "                 SGDClassifier(class_weight='balanced', loss='log',\n",
       "                               max_iter=5000, n_jobs=-1, random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "enhanced-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe3 = pipe3.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "rough-suicide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6092957081788654\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_pipe3, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "median-reflection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.69      0.67      0.68       384\n",
      "         low       0.62      0.32      0.42       120\n",
      "      medium       0.69      0.77      0.73       596\n",
      "\n",
      "    accuracy                           0.69      1100\n",
      "   macro avg       0.67      0.59      0.61      1100\n",
      "weighted avg       0.68      0.69      0.68      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-fifteen",
   "metadata": {},
   "source": [
    "# 3. Combining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "english-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, dev = train_test_split(df, \n",
    "                             test_size=0.1,\n",
    "                             random_state=1,\n",
    "                             shuffle=True,\n",
    "                             stratify = df.Proficiency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "absolute-authorization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    5368\n",
       "high      3451\n",
       "low       1081\n",
       "Name: Proficiency, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Proficiency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "turned-dispatch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    596\n",
       "high      384\n",
       "low       120\n",
       "Name: Proficiency, dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.Proficiency.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "demanding-database",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>1664392.txt</td>\n",
       "      <td>I am in complete agreement of the statement th...</td>\n",
       "      <td>HIN</td>\n",
       "      <td>high</td>\n",
       "      <td>PRP VBP IN JJ NN IN DT NN IN PRP$ RBR JJ IN NN...</td>\n",
       "      <td>-PRON- be in complete agreement of the stateme...</td>\n",
       "      <td>306</td>\n",
       "      <td>15</td>\n",
       "      <td>1783</td>\n",
       "      <td>i am in of the that its more for to and than i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2382</th>\n",
       "      <td>434670.txt</td>\n",
       "      <td>Of course I agree to the statement that we hav...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>medium</td>\n",
       "      <td>RB RB PRP VBP IN DT NN IN PRP VBP TO VB RB JJ ...</td>\n",
       "      <td>of course -PRON- agree to the statement that -...</td>\n",
       "      <td>319</td>\n",
       "      <td>15</td>\n",
       "      <td>1756</td>\n",
       "      <td>of i to the that we have to be of the are each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8011</th>\n",
       "      <td>1450658.txt</td>\n",
       "      <td>During my study I learned a lot about advertis...</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN PRP$ NN PRP VBD DT NN IN NNS . PRP$ NN RB V...</td>\n",
       "      <td>during -PRON- study -PRON- learn a lot about a...</td>\n",
       "      <td>315</td>\n",
       "      <td>13</td>\n",
       "      <td>1784</td>\n",
       "      <td>during my i a about our that should to a but n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>63277.txt</td>\n",
       "      <td>I agree the opinion that most advertisements m...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>medium</td>\n",
       "      <td>PRP VBP DT NN IN JJS NNS VBP NNS VB RBR IN PRP...</td>\n",
       "      <td>-PRON- agree the opinion that most advertiseme...</td>\n",
       "      <td>237</td>\n",
       "      <td>16</td>\n",
       "      <td>1439</td>\n",
       "      <td>i the that most than they now we in the in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>372234.txt</td>\n",
       "      <td>There are some advantages in beeing versed reg...</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>EX VBP DT NNS IN NN VBD VBG DT JJ NN RB RB IN ...</td>\n",
       "      <td>there be some advantage in beeing verse regard...</td>\n",
       "      <td>339</td>\n",
       "      <td>19</td>\n",
       "      <td>1911</td>\n",
       "      <td>there are some in a as as having about a of it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Filename                                               text Language  \\\n",
       "9134  1664392.txt  I am in complete agreement of the statement th...      HIN   \n",
       "2382   434670.txt  Of course I agree to the statement that we hav...      KOR   \n",
       "8011  1450658.txt  During my study I learned a lot about advertis...      DEU   \n",
       "345     63277.txt  I agree the opinion that most advertisements m...      KOR   \n",
       "2045   372234.txt  There are some advantages in beeing versed reg...      DEU   \n",
       "\n",
       "     Proficiency                                           pos_tags  \\\n",
       "9134        high  PRP VBP IN JJ NN IN DT NN IN PRP$ RBR JJ IN NN...   \n",
       "2382      medium  RB RB PRP VBP IN DT NN IN PRP VBP TO VB RB JJ ...   \n",
       "8011      medium  IN PRP$ NN PRP VBD DT NN IN NNS . PRP$ NN RB V...   \n",
       "345       medium  PRP VBP DT NN IN JJS NNS VBP NNS VB RBR IN PRP...   \n",
       "2045      medium  EX VBP DT NNS IN NN VBD VBG DT JJ NN RB RB IN ...   \n",
       "\n",
       "                                             lemma_text  n_words  n_sentences  \\\n",
       "9134  -PRON- be in complete agreement of the stateme...      306           15   \n",
       "2382  of course -PRON- agree to the statement that -...      319           15   \n",
       "8011  during -PRON- study -PRON- learn a lot about a...      315           13   \n",
       "345   -PRON- agree the opinion that most advertiseme...      237           16   \n",
       "2045  there be some advantage in beeing verse regard...      339           19   \n",
       "\n",
       "      doc_length                                         stop_words  \n",
       "9134        1783  i am in of the that its more for to and than i...  \n",
       "2382        1756  of i to the that we have to be of the are each...  \n",
       "8011        1784  during my i a about our that should to a but n...  \n",
       "345         1439  i the that most than they now we in the in the...  \n",
       "2045        1911  there are some in a as as having about a of it...  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-constraint",
   "metadata": {},
   "source": [
    "## 3.1. Combo 1. (LogisticRegression). Token *n*-grams (1,3), number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "placed-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"text\", \"n_words\"]]\n",
    "y_train = train['Proficiency']\n",
    "\n",
    "X_dev = dev[[\"text\", \"n_words\"]]\n",
    "y_dev = dev['Proficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ceramic-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect_tokens = CountVectorizer(tokenizer=nltk__word_tokenizer, ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # mean=False to allow to work with sparse vector\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (cvect_tokens, \"text\"), \n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(multi_class=\"ovr\",\n",
    "                            class_weight=\"balanced\", # uses value of y to automatically adjust weights inversely proportional to class frequencies\n",
    "                            max_iter = 5000,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "responsible-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo1 = make_pipeline(preprocessor, logreg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "welcome-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  33.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total= 7.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(with_mean=False),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('countvectorizer',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function word_tokenize at 0x7fecec69eb80>),\n",
       "                                                  'text')])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=5000,\n",
       "                                    multi_class='ovr', n_jobs=-1,\n",
       "                                    random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "social-burner",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo1 = combo1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "boolean-stick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7234926290317469\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_combo1, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "sonic-thumb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.74      0.74      0.74       384\n",
      "         low       0.67      0.65      0.66       120\n",
      "      medium       0.76      0.77      0.77       596\n",
      "\n",
      "    accuracy                           0.75      1100\n",
      "   macro avg       0.73      0.72      0.72      1100\n",
      "weighted avg       0.75      0.75      0.75      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-server",
   "metadata": {},
   "source": [
    "## 3.2. Combo 2. (LogisticRegression). Lemma *n*-grams (1,3), number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "proved-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"lemma_text\", \"n_words\"]]\n",
    "y_train = train['Proficiency']\n",
    "\n",
    "X_dev = dev[[\"lemma_text\", \"n_words\"]]\n",
    "y_dev = dev['Proficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "closed-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect_tokens = CountVectorizer(tokenizer=nltk__word_tokenizer, ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # mean=False to allow to work with sparse vector\n",
    "\n",
    "preprocessor2 = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (cvect_tokens, \"lemma_text\"), \n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "logreg2 = LogisticRegression(multi_class=\"ovr\",\n",
    "                            class_weight=\"balanced\", # uses value of y to automatically adjust weights inversely proportional to class frequencies\n",
    "                            max_iter = 5000,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "prostate-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo2 = make_pipeline(preprocessor2, logreg2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "terminal-climb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  30.7s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total= 7.7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(with_mean=False),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('countvectorizer',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function word_tokenize at 0x7fecec69eb80>),\n",
       "                                                  'lemma_text')])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=5000,\n",
       "                                    multi_class='ovr', n_jobs=-1,\n",
       "                                    random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "infectious-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo2 = combo2.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ready-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7080966071986734\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_combo2, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dynamic-fluid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.74      0.74      0.74       384\n",
      "         low       0.67      0.65      0.66       120\n",
      "      medium       0.76      0.77      0.77       596\n",
      "\n",
      "    accuracy                           0.75      1100\n",
      "   macro avg       0.73      0.72      0.72      1100\n",
      "weighted avg       0.75      0.75      0.75      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-biodiversity",
   "metadata": {},
   "source": [
    "## 3.3. Combo 3. (LogisticRegression). Token *n*-grams, number of tokens, pos_tags <u>(BEST PERFORMING CLASSIFIER)</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "persistent-produce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "incident-blues",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high\n",
      "medium\n",
      "low\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'high': 363.2454361054767,\n",
       " 'medium': 306.26657973174366,\n",
       " 'low': 206.29232192414432}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_dict = {}\n",
    "for level in train.Proficiency.unique(): \n",
    "    print(level)\n",
    "    level_dict[level] = mean(train[train[\"Proficiency\"]==level][\"n_words\"])\n",
    "    \n",
    "level_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "central-gross",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"text\", \"n_words\", \"pos_tags\"]]\n",
    "y_train = train['Proficiency']\n",
    "\n",
    "X_dev = dev[[\"text\", \"n_words\", \"pos_tags\"]]\n",
    "y_dev = dev['Proficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "regular-copying",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect_tokens = CountVectorizer(tokenizer=nltk__word_tokenizer, \n",
    "                               ngram_range=(1,3))\n",
    "\n",
    "cvect_pos = CountVectorizer(max_features = 1000,\n",
    "                           ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # mean=False to allow to work with sparse vector\n",
    "\n",
    "preprocessor3 = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (cvect_tokens, \"text\"), \n",
    "    (cvect_pos, \"pos_tags\"),\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "logreg3 = LogisticRegression(multi_class=\"ovr\",\n",
    "                            class_weight=\"balanced\", # uses value of y to automatically adjust weights inversely proportional to class frequencies\n",
    "                            max_iter = 5000,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "prompt-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo3 = make_pipeline(preprocessor3, logreg3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "powerful-therapy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  40.0s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=20.1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(with_mean=False),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('countvectorizer-1',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function word_tokenize at 0x7fecec69eb80>),\n",
       "                                                  'text'),\n",
       "                                                 ('countvectorizer-2',\n",
       "                                                  CountVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3)),\n",
       "                                                  'pos_tags')])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=5000,\n",
       "                                    multi_class='ovr', n_jobs=-1,\n",
       "                                    random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "wound-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo3 = combo3.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "universal-penetration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7323710965912943\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_combo3, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "studied-programming",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.75      0.74      0.75       384\n",
      "         low       0.68      0.67      0.68       120\n",
      "      medium       0.77      0.78      0.78       596\n",
      "\n",
      "    accuracy                           0.75      1100\n",
      "   macro avg       0.73      0.73      0.73      1100\n",
      "weighted avg       0.75      0.75      0.75      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "brazilian-computer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_dev, y_pred_combo3, rownames=['Actual'], colnames=['Predicted']) \n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-shareware",
   "metadata": {},
   "source": [
    "## 3.4. Combo 4. (LogisticRegression). Token *n*-grams (1,3), number of tokens, POS-tags, function words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "neither-daughter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"text\", \"n_words\", \"pos_tags\", \"stop_words\"]]\n",
    "y_train = train['Proficiency']\n",
    "\n",
    "X_dev = dev[[\"text\", \"n_words\", \"pos_tags\", \"stop_words\"]]\n",
    "y_dev = dev['Proficiency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "obvious-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect_tokens = CountVectorizer(tokenizer=nltk__word_tokenizer, \n",
    "                               ngram_range=(1,3))\n",
    "\n",
    "cvect_pos = CountVectorizer(max_features = 1000,\n",
    "                           ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # mean=False to allow to work with sparse vector\n",
    "\n",
    "preprocessor4 = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (cvect_tokens, \"text\"),\n",
    "    (cvect_tokens, \"stop_words\"),\n",
    "    (cvect_pos, \"pos_tags\"),\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "logreg4 = LogisticRegression(multi_class=\"ovr\",\n",
    "                            class_weight=\"balanced\", # uses value of y to automatically adjust weights inversely proportional to class frequencies\n",
    "                            max_iter = 5000,\n",
    "                            n_jobs = -1,\n",
    "                            random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "renewable-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo4 = make_pipeline(preprocessor4, logreg4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "official-reasoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  45.3s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=21.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(with_mean=False),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('countvectorizer-1',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function word_tokenize at 0x7fecec69eb80>),\n",
       "                                                  'text'),\n",
       "                                                 ('countvectorizer-2',\n",
       "                                                  CountVectorizer(ngram_range=(1,\n",
       "                                                                               3),\n",
       "                                                                  tokenizer=<function word_tokenize at 0x7fecec69eb80>),\n",
       "                                                  'stop_words'),\n",
       "                                                 ('countvectorizer-3',\n",
       "                                                  CountVectorizer(max_features=1000,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3)),\n",
       "                                                  'pos_tags')])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=5000,\n",
       "                                    multi_class='ovr', n_jobs=-1,\n",
       "                                    random_state=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "naval-queensland",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo4 = combo4.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "saved-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7317773391885026\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_dev, y_pred_combo4, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "opposed-differential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.75      0.74      0.75       384\n",
      "         low       0.66      0.68      0.67       120\n",
      "      medium       0.78      0.78      0.78       596\n",
      "\n",
      "    accuracy                           0.76      1100\n",
      "   macro avg       0.73      0.73      0.73      1100\n",
      "weighted avg       0.76      0.76      0.76      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
