{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "requested-destruction",
   "metadata": {},
   "source": [
    "# NLP Shared Task 2021\n",
    "\n",
    "## Native Language Identification\n",
    "Pauline Claes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-soccer",
   "metadata": {},
   "source": [
    "## 1. Loading modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "separate-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/paulineclaes/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk__word_tokenizer = word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "from spacy.lang.en import English\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_list = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-processor",
   "metadata": {},
   "source": [
    "## 2. Preprocessing of the train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promising-formula",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "criminal-basic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TUR    1000\n",
       "KOR    1000\n",
       "JPN    1000\n",
       "ARA    1000\n",
       "FRA    1000\n",
       "TEL    1000\n",
       "ITA    1000\n",
       "SPA    1000\n",
       "HIN    1000\n",
       "DEU    1000\n",
       "ZHO    1000\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fewer-crest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Proficiency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.txt</td>\n",
       "      <td>Some people might think that traveling in a gr...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278.txt</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348.txt</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666.txt</td>\n",
       "      <td>Some people believe that young people can enjo...</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733.txt</td>\n",
       "      <td>Travelling is  usually considered as good recr...</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                               text Language  \\\n",
       "0   88.txt  Some people might think that traveling in a gr...      KOR   \n",
       "1  278.txt  IThe importance and popularity of travelling i...      DEU   \n",
       "2  348.txt  It is an important decision, how to plan your ...      TUR   \n",
       "3  666.txt  Some people believe that young people can enjo...      ZHO   \n",
       "4  733.txt  Travelling is  usually considered as good recr...      TEL   \n",
       "\n",
       "  Proficiency  \n",
       "0        high  \n",
       "1      medium  \n",
       "2        high  \n",
       "3      medium  \n",
       "4      medium  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hollywood-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tag(doc):\n",
    "    return \" \".join([token.tag_ for token in nlp(doc)])\n",
    "\n",
    "def lemmatizer(doc):\n",
    "    return \" \".join([token.lemma_ for token in nlp(doc)])\n",
    "\n",
    "def stop_words(doc):\n",
    "    return \" \".join([w for w in doc.lower().split() if w in stop_words_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continuous-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding pos_tag column\n",
    "df[\"pos_tags\"] = df.text.apply(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "weekly-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding lemmatized text column\n",
    "df[\"lemma_text\"] = df.text.apply(lemmatizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transsexual-destruction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with stop_words (function words)\n",
    "df[\"stop_words\"] = df.text.apply(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "given-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with text length in number of words\n",
    "df[\"n_words\"] = df[\"text\"].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tired-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with text length in number of sentences\n",
    "df[\"n_sentences\"] = [text.count(\".\") for text in df[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "raising-recorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding column with text length in number of characters\n",
    "df[\"doc_length\"] = df.text.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "formal-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving preprocessed DataFrame to CSV, to not have to run it again \n",
    "# every time. This df will be read in again, and we will move forward\n",
    "# with this dataframe.\n",
    "# df.to_csv(\"train_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absent-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exciting-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>text</th>\n",
       "      <th>Language</th>\n",
       "      <th>Proficiency</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>lemma_text</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>doc_length</th>\n",
       "      <th>stop_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.txt</td>\n",
       "      <td>Some people might think that traveling in a gr...</td>\n",
       "      <td>KOR</td>\n",
       "      <td>high</td>\n",
       "      <td>DT NNS MD VB IN VBG IN DT NN VBN IN DT NN NN V...</td>\n",
       "      <td>some people may think that travel in a group l...</td>\n",
       "      <td>384</td>\n",
       "      <td>16</td>\n",
       "      <td>1940</td>\n",
       "      <td>some that in a by a is a a has its and does no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>278.txt</td>\n",
       "      <td>IThe importance and popularity of travelling i...</td>\n",
       "      <td>DEU</td>\n",
       "      <td>medium</td>\n",
       "      <td>IN NN CC NN IN VBG VBZ RB VBG , _SP NN VBZ JJ ...</td>\n",
       "      <td>ithe importance and popularity of travel be st...</td>\n",
       "      <td>321</td>\n",
       "      <td>13</td>\n",
       "      <td>1645</td>\n",
       "      <td>and of is is in to other and but the how to do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348.txt</td>\n",
       "      <td>It is an important decision, how to plan your ...</td>\n",
       "      <td>TUR</td>\n",
       "      <td>high</td>\n",
       "      <td>PRP VBZ DT JJ NN , WRB TO VB PRP$ NN . DT NNS ...</td>\n",
       "      <td>-PRON- be an important decision , how to plan ...</td>\n",
       "      <td>360</td>\n",
       "      <td>15</td>\n",
       "      <td>2022</td>\n",
       "      <td>it is an how to your some to a of and their so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>666.txt</td>\n",
       "      <td>Some people believe that young people can enjo...</td>\n",
       "      <td>ZHO</td>\n",
       "      <td>medium</td>\n",
       "      <td>DT NNS VBP IN JJ NNS MD VB NN JJR IN JJR NN VB...</td>\n",
       "      <td>some people believe that young people can enjo...</td>\n",
       "      <td>347</td>\n",
       "      <td>26</td>\n",
       "      <td>1891</td>\n",
       "      <td>some that can more than from my of the is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>733.txt</td>\n",
       "      <td>Travelling is  usually considered as good recr...</td>\n",
       "      <td>TEL</td>\n",
       "      <td>medium</td>\n",
       "      <td>NNP VBZ _SP RB VBN IN JJ NN _SP IN JJ NNS , IN...</td>\n",
       "      <td>Travelling be   usually consider as good recre...</td>\n",
       "      <td>349</td>\n",
       "      <td>13</td>\n",
       "      <td>1862</td>\n",
       "      <td>is as by as for and it is to have some and a w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Filename                                               text Language  \\\n",
       "0   88.txt  Some people might think that traveling in a gr...      KOR   \n",
       "1  278.txt  IThe importance and popularity of travelling i...      DEU   \n",
       "2  348.txt  It is an important decision, how to plan your ...      TUR   \n",
       "3  666.txt  Some people believe that young people can enjo...      ZHO   \n",
       "4  733.txt  Travelling is  usually considered as good recr...      TEL   \n",
       "\n",
       "  Proficiency                                           pos_tags  \\\n",
       "0        high  DT NNS MD VB IN VBG IN DT NN VBN IN DT NN NN V...   \n",
       "1      medium  IN NN CC NN IN VBG VBZ RB VBG , _SP NN VBZ JJ ...   \n",
       "2        high  PRP VBZ DT JJ NN , WRB TO VB PRP$ NN . DT NNS ...   \n",
       "3      medium  DT NNS VBP IN JJ NNS MD VB NN JJR IN JJR NN VB...   \n",
       "4      medium  NNP VBZ _SP RB VBN IN JJ NN _SP IN JJ NNS , IN...   \n",
       "\n",
       "                                          lemma_text  n_words  n_sentences  \\\n",
       "0  some people may think that travel in a group l...      384           16   \n",
       "1  ithe importance and popularity of travel be st...      321           13   \n",
       "2  -PRON- be an important decision , how to plan ...      360           15   \n",
       "3  some people believe that young people can enjo...      347           26   \n",
       "4  Travelling be   usually consider as good recre...      349           13   \n",
       "\n",
       "   doc_length                                         stop_words  \n",
       "0        1940  some that in a by a is a a has its and does no...  \n",
       "1        1645  and of is is in to other and but the how to do...  \n",
       "2        2022  it is an how to your some to a of and their so...  \n",
       "3        1891  some that can more than from my of the is the ...  \n",
       "4        1862  is as by as for and it is to have some and a w...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "direct-polyester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11000 entries, 0 to 10999\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Filename     11000 non-null  object\n",
      " 1   text         11000 non-null  object\n",
      " 2   Language     11000 non-null  object\n",
      " 3   Proficiency  11000 non-null  object\n",
      " 4   pos_tags     11000 non-null  object\n",
      " 5   lemma_text   11000 non-null  object\n",
      " 6   n_words      11000 non-null  int64 \n",
      " 7   n_sentences  11000 non-null  int64 \n",
      " 8   doc_length   11000 non-null  int64 \n",
      " 9   stop_words   11000 non-null  object\n",
      "dtypes: int64(3), object(7)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sixth-coaching",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_sentences</th>\n",
       "      <th>doc_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "      <td>11000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>315.093182</td>\n",
       "      <td>16.100909</td>\n",
       "      <td>1787.637182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.407150</td>\n",
       "      <td>5.716632</td>\n",
       "      <td>517.057569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>278.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1567.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>315.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1784.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>355.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2017.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>799.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>29870.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            n_words   n_sentences    doc_length\n",
       "count  11000.000000  11000.000000  11000.000000\n",
       "mean     315.093182     16.100909   1787.637182\n",
       "std       77.407150      5.716632    517.057569\n",
       "min        2.000000      0.000000      9.000000\n",
       "25%      278.000000     12.000000   1567.000000\n",
       "50%      315.000000     16.000000   1784.000000\n",
       "75%      355.000000     20.000000   2017.000000\n",
       "max      799.000000     74.000000  29870.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "exempt-constitutional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HIN    1000\n",
       "SPA    1000\n",
       "FRA    1000\n",
       "JPN    1000\n",
       "TUR    1000\n",
       "DEU    1000\n",
       "KOR    1000\n",
       "ARA    1000\n",
       "ITA    1000\n",
       "ZHO    1000\n",
       "TEL    1000\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "japanese-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.text.values\n",
    "y = df.Language.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "after-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_dev, y_train, y_dev = train_test_split(X,\n",
    "                                                  y, \n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-place",
   "metadata": {},
   "source": [
    "## 3. Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-photograph",
   "metadata": {},
   "source": [
    "### 3.1. Dummy Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ready-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "catholic-holder",
   "metadata": {},
   "source": [
    "#### 3.1.1. Dummy Classifier with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "duplicate-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "regulated-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvect = cvect.fit_transform(X_train)\n",
    "X_dev_cvect = cvect.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "afraid-clarity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='stratified')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(X_train_cvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "exact-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = dummy_clf.predict(X_dev_cvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "contained-southeast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08363636363636363\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "corrected-mount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.06      0.05      0.05       100\n",
      "         DEU       0.08      0.09      0.08       100\n",
      "         FRA       0.09      0.09      0.09       100\n",
      "         HIN       0.07      0.08      0.08       100\n",
      "         ITA       0.06      0.05      0.06       100\n",
      "         JPN       0.09      0.09      0.09       100\n",
      "         KOR       0.08      0.08      0.08       100\n",
      "         SPA       0.07      0.07      0.07       100\n",
      "         TEL       0.14      0.17      0.16       100\n",
      "         TUR       0.11      0.12      0.12       100\n",
      "         ZHO       0.03      0.03      0.03       100\n",
      "\n",
      "    accuracy                           0.08      1100\n",
      "   macro avg       0.08      0.08      0.08      1100\n",
      "weighted avg       0.08      0.08      0.08      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-titanium",
   "metadata": {},
   "source": [
    "#### 3.1.2. Dummy Classifier with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ignored-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "legitimate-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_dev_tfidf = tfidf.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "broken-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(random_state=1, strategy='stratified')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "indirect-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dummy = dummy_clf.predict(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "described-outdoors",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08363636363636363\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "experimental-imperial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.06      0.05      0.05       100\n",
      "         DEU       0.08      0.09      0.08       100\n",
      "         FRA       0.09      0.09      0.09       100\n",
      "         HIN       0.07      0.08      0.08       100\n",
      "         ITA       0.06      0.05      0.06       100\n",
      "         JPN       0.09      0.09      0.09       100\n",
      "         KOR       0.08      0.08      0.08       100\n",
      "         SPA       0.07      0.07      0.07       100\n",
      "         TEL       0.14      0.17      0.16       100\n",
      "         TUR       0.11      0.12      0.12       100\n",
      "         ZHO       0.03      0.03      0.03       100\n",
      "\n",
      "    accuracy                           0.08      1100\n",
      "   macro avg       0.08      0.08      0.08      1100\n",
      "weighted avg       0.08      0.08      0.08      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-alexander",
   "metadata": {},
   "source": [
    "### 3.2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-discussion",
   "metadata": {},
   "source": [
    "#### 3.2.1. SVM with CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "needed-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "anonymous-thermal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_cvect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "mysterious-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_dev_cvect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "olympic-vatican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6036363636363636\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "monthly-access",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.55      0.55      0.55       100\n",
      "         DEU       0.76      0.72      0.74       100\n",
      "         FRA       0.60      0.61      0.60       100\n",
      "         HIN       0.56      0.58      0.57       100\n",
      "         ITA       0.66      0.66      0.66       100\n",
      "         JPN       0.51      0.60      0.55       100\n",
      "         KOR       0.59      0.52      0.55       100\n",
      "         SPA       0.52      0.54      0.53       100\n",
      "         TEL       0.64      0.68      0.66       100\n",
      "         TUR       0.68      0.58      0.63       100\n",
      "         ZHO       0.61      0.60      0.60       100\n",
      "\n",
      "    accuracy                           0.60      1100\n",
      "   macro avg       0.61      0.60      0.60      1100\n",
      "weighted avg       0.61      0.60      0.60      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-commissioner",
   "metadata": {},
   "source": [
    "#### 3.2.2. SVM with TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fleet-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "utility-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "selected-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = svm.predict(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "separated-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7227272727272728\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "touched-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.70      0.63      0.66       100\n",
      "         DEU       0.84      0.83      0.83       100\n",
      "         FRA       0.76      0.73      0.74       100\n",
      "         HIN       0.59      0.69      0.64       100\n",
      "         ITA       0.87      0.77      0.81       100\n",
      "         JPN       0.69      0.73      0.71       100\n",
      "         KOR       0.71      0.66      0.68       100\n",
      "         SPA       0.67      0.74      0.70       100\n",
      "         TEL       0.75      0.70      0.73       100\n",
      "         TUR       0.79      0.77      0.78       100\n",
      "         ZHO       0.64      0.70      0.67       100\n",
      "\n",
      "    accuracy                           0.72      1100\n",
      "   macro avg       0.73      0.72      0.72      1100\n",
      "weighted avg       0.73      0.72      0.72      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-johnson",
   "metadata": {},
   "source": [
    "### 3.3. BERT\n",
    "Please check separate notebook for BERT baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-canvas",
   "metadata": {},
   "source": [
    "##  4. Pipeline models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-cedar",
   "metadata": {},
   "source": [
    "### 4.1. Pipe 1. Logistic Regression and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cubic-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression() # default parameters\n",
    "tfidf = TfidfVectorizer() # default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "beginning-darwin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline(tfidf, log_reg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "parallel-easter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   2.0s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=  10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paulineclaes/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('logisticregression', LogisticRegression())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "third-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe1 = pipe1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "harmful-execution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7190909090909091\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_pipe1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "median-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.76      0.59      0.66       100\n",
      "         DEU       0.82      0.85      0.83       100\n",
      "         FRA       0.77      0.78      0.78       100\n",
      "         HIN       0.60      0.66      0.63       100\n",
      "         ITA       0.76      0.77      0.77       100\n",
      "         JPN       0.67      0.68      0.68       100\n",
      "         KOR       0.72      0.68      0.70       100\n",
      "         SPA       0.70      0.67      0.68       100\n",
      "         TEL       0.70      0.74      0.72       100\n",
      "         TUR       0.76      0.74      0.75       100\n",
      "         ZHO       0.68      0.75      0.71       100\n",
      "\n",
      "    accuracy                           0.72      1100\n",
      "   macro avg       0.72      0.72      0.72      1100\n",
      "weighted avg       0.72      0.72      0.72      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polished-reduction",
   "metadata": {},
   "source": [
    "#### 4.1.1. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "complete-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1_params = [{'tfidfvectorizer__lowercase' : [True, False], \n",
    "                 'tfidfvectorizer__max_df' : [0.70, 0.75, 0.80, 0.85, 0.90, 1.0],\n",
    "                 'tfidfvectorizer__min_df' : [0.001, 0.01, 0.1],\n",
    "                 'tfidfvectorizer__ngram_range' : [(1,1), (1,2), (1,3), (1,4)],\n",
    "                 'tfidfvectorizer__norm' : ['l1', 'l2'],\n",
    "                 'tfidfvectorizer__tokenizer' : [nltk__word_tokenizer],\n",
    "                 'logisticregression__C' : [0.01, 0.1, 1.0, 10.0],\n",
    "                 'logisticregression__max_iter': [1000, 2500, 5000],\n",
    "                 'logisticregression__multi_class' : ['ovr', 'multinomial']}]\n",
    "\n",
    "rs_pipe1 = RandomizedSearchCV(estimator = pipe1,\n",
    "                              param_distributions = pipe1_params, \n",
    "                              n_iter = 15, \n",
    "                              scoring = 'accuracy', \n",
    "                             refit=True, \n",
    "                             cv=10, \n",
    "                             verbose=1,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "demographic-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  17.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer()),\n",
       "                                             ('logisticregression',\n",
       "                                              LogisticRegression())],\n",
       "                                      verbose=True),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions=[{'logisticregression__C': [0.01, 0.1,\n",
       "                                                                   1.0, 10.0],\n",
       "                                         'logisticregression__max_iter': [1000,\n",
       "                                                                          2500,\n",
       "                                                                          5000],\n",
       "                                         'logisticregression__multi_class': ['ovr',\n",
       "                                                                             'multinomial'],\n",
       "                                         'tfidfvectorizer__lowercase': [True,\n",
       "                                                                        False],\n",
       "                                         'tfidfvectorizer__max_df': [0.7, 0.75,\n",
       "                                                                     0.8, 0.85,\n",
       "                                                                     0.9, 1.0],\n",
       "                                         'tfidfvectorizer__min_df': [0.001,\n",
       "                                                                     0.01,\n",
       "                                                                     0.1],\n",
       "                                         'tfidfvectorizer__ngram_range': [(1,\n",
       "                                                                           1),\n",
       "                                                                          (1,\n",
       "                                                                           2),\n",
       "                                                                          (1,\n",
       "                                                                           3),\n",
       "                                                                          (1,\n",
       "                                                                           4)],\n",
       "                                         'tfidfvectorizer__norm': ['l1', 'l2'],\n",
       "                                         'tfidfvectorizer__tokenizer': [<function word_tokenize at 0x7fd5714a2160>]}],\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_pipe1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "functioning-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_pipe1_best = rs_pipe1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "sensitive-behavior",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidfvectorizer__tokenizer': <function word_tokenize at 0x7fd5714a2160>, 'tfidfvectorizer__norm': 'l2', 'tfidfvectorizer__ngram_range': (1, 1), 'tfidfvectorizer__min_df': 0.001, 'tfidfvectorizer__max_df': 0.8, 'tfidfvectorizer__lowercase': False, 'logisticregression__multi_class': 'ovr', 'logisticregression__max_iter': 2500, 'logisticregression__C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(rs_pipe1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-glory",
   "metadata": {},
   "source": [
    "### 4.2. Pipe 2. Stochastic Gradient Descent Classifier and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "administrative-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier() # default parameters\n",
    "tfidf = TfidfVectorizer() # default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "paperback-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = make_pipeline(tfidf, sgd, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "august-humanity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   1.7s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   0.6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('sgdclassifier', SGDClassifier())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "robust-restaurant",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe2 = pipe2.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "impossible-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7554545454545455\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_pipe2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "arctic-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.76      0.63      0.69       100\n",
      "         DEU       0.82      0.89      0.86       100\n",
      "         FRA       0.79      0.81      0.80       100\n",
      "         HIN       0.65      0.59      0.62       100\n",
      "         ITA       0.84      0.87      0.86       100\n",
      "         JPN       0.74      0.74      0.74       100\n",
      "         KOR       0.67      0.68      0.68       100\n",
      "         SPA       0.74      0.66      0.70       100\n",
      "         TEL       0.71      0.82      0.76       100\n",
      "         TUR       0.75      0.80      0.78       100\n",
      "         ZHO       0.81      0.82      0.82       100\n",
      "\n",
      "    accuracy                           0.76      1100\n",
      "   macro avg       0.75      0.76      0.75      1100\n",
      "weighted avg       0.75      0.76      0.75      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-arctic",
   "metadata": {},
   "source": [
    "#### 4.2.1. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "treated-council",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2_params = [{'tfidfvectorizer__lowercase' : [True, False], \n",
    "                 'tfidfvectorizer__max_df' : [0.70, 0.75, 0.80, 0.85, 0.90, 1.0],\n",
    "                 'tfidfvectorizer__min_df' : [0.001, 0.01, 0.1],\n",
    "                 'tfidfvectorizer__ngram_range' : [(1,1), (1,2), (1,3), (1,4)],\n",
    "                 'tfidfvectorizer__norm' : ['l1', 'l2'],\n",
    "                 'tfidfvectorizer__tokenizer' : [nltk__word_tokenizer],\n",
    "                 'sgdclassifier__loss' : ['hinge', 'log', 'squared_hinge'],\n",
    "                 'sgdclassifier__penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "                 'sgdclassifier__alpha' : [1e-4, 1e-3, 0.01, 0.1, 1.0],\n",
    "                 'sgdclassifier__max_iter': [1000, 2500, 5000]}] \n",
    "\n",
    "rs_pipe2 = RandomizedSearchCV(estimator = pipe2,\n",
    "                              param_distributions = pipe2_params, \n",
    "                              n_iter = 15, \n",
    "                              scoring = 'accuracy', \n",
    "                              refit=True, \n",
    "                              cv=10, \n",
    "                              verbose=1, \n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aggregate-colonial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  31.6s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer()),\n",
       "                                             ('sgdclassifier',\n",
       "                                              SGDClassifier())],\n",
       "                                      verbose=True),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions=[{'sgdclassifier__alpha': [0.0001, 0.001,\n",
       "                                                                  0.01, 0.1,\n",
       "                                                                  1.0],\n",
       "                                         'sgdclassifier__loss': ['hinge', 'log',\n",
       "                                                                 'squared_hinge'],\n",
       "                                         'sgdclassifier__max_iter': [1000, 2500,\n",
       "                                                                     5000],\n",
       "                                         'sgdclassifier__penalt...',\n",
       "                                                                    'elasticnet'],\n",
       "                                         'tfidfvectorizer__lowercase': [True,\n",
       "                                                                        False],\n",
       "                                         'tfidfvectorizer__max_df': [0.7, 0.75,\n",
       "                                                                     0.8, 0.85,\n",
       "                                                                     0.9, 1.0],\n",
       "                                         'tfidfvectorizer__min_df': [0.001,\n",
       "                                                                     0.01,\n",
       "                                                                     0.1],\n",
       "                                         'tfidfvectorizer__ngram_range': [(1,\n",
       "                                                                           1),\n",
       "                                                                          (1,\n",
       "                                                                           2),\n",
       "                                                                          (1,\n",
       "                                                                           3),\n",
       "                                                                          (1,\n",
       "                                                                           4)],\n",
       "                                         'tfidfvectorizer__norm': ['l1', 'l2'],\n",
       "                                         'tfidfvectorizer__tokenizer': [<function word_tokenize at 0x7fd5714a2160>]}],\n",
       "                   scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_pipe2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "sublime-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_pipe2_best = rs_pipe2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acute-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tfidfvectorizer__tokenizer': <function word_tokenize at 0x7fd5714a2160>, 'tfidfvectorizer__norm': 'l2', 'tfidfvectorizer__ngram_range': (1, 4), 'tfidfvectorizer__min_df': 0.1, 'tfidfvectorizer__max_df': 1.0, 'tfidfvectorizer__lowercase': True, 'sgdclassifier__penalty': 'l1', 'sgdclassifier__max_iter': 1000, 'sgdclassifier__loss': 'hinge', 'sgdclassifier__alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "print(rs_pipe2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-brass",
   "metadata": {},
   "source": [
    "### 4.3. Pipe 3. LinearSVC and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "prepared-music",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_svc = LinearSVC() # default parameters\n",
    "tfidf = TfidfVectorizer() # default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "radical-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe3 = make_pipeline(tfidf, linear_svc, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "numerical-hostel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=   1.7s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   1.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('linearsvc', LinearSVC())],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "artistic-lloyd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipe3 = pipe3.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "casual-universe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_pipe3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "according-processing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.72      0.64      0.68       100\n",
      "         DEU       0.87      0.87      0.87       100\n",
      "         FRA       0.79      0.84      0.81       100\n",
      "         HIN       0.71      0.68      0.69       100\n",
      "         ITA       0.88      0.86      0.87       100\n",
      "         JPN       0.72      0.74      0.73       100\n",
      "         KOR       0.69      0.69      0.69       100\n",
      "         SPA       0.77      0.71      0.74       100\n",
      "         TEL       0.73      0.80      0.76       100\n",
      "         TUR       0.75      0.78      0.76       100\n",
      "         ZHO       0.78      0.79      0.79       100\n",
      "\n",
      "    accuracy                           0.76      1100\n",
      "   macro avg       0.76      0.76      0.76      1100\n",
      "weighted avg       0.76      0.76      0.76      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_pipe3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-digit",
   "metadata": {},
   "source": [
    "#### 4.3.1. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "organic-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_pipe3_params = [{'tfidfvectorizer__lowercase' : [True, False], \n",
    "                     'tfidfvectorizer__max_df' : [0.70, 0.75, 0.80, 0.85, 0.90, 1.0],\n",
    "                     'tfidfvectorizer__min_df' : [0.001, 0.01, 0.1],\n",
    "                     'tfidfvectorizer__ngram_range' : [(1,1), (1,2), (1,3), (1,4)],\n",
    "                     'tfidfvectorizer__norm' : ['l1', 'l2'],\n",
    "                     'tfidfvectorizer__tokenizer' : [nltk__word_tokenizer],\n",
    "                     'linearsvc__C' : [0.1, 1.0, 10.0],\n",
    "                     'linearsvc__max_iter' : [1000, 2500, 5000]}]\n",
    "\n",
    "rs_pipe3 = RandomizedSearchCV(estimator = pipe3, \n",
    "                              param_distributions=rs_pipe3_params, \n",
    "                              n_iter = 15, \n",
    "                              scoring='accuracy', \n",
    "                              refit=True, \n",
    "                              cv=10, \n",
    "                              verbose=2,\n",
    "                              random_state=1,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "canadian-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  27.3s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   3.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('tfidfvectorizer',\n",
       "                                              TfidfVectorizer()),\n",
       "                                             ('linearsvc', LinearSVC())],\n",
       "                                      verbose=True),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions=[{'linearsvc__C': [0.1, 1.0, 10.0],\n",
       "                                         'linearsvc__max_iter': [1000, 2500,\n",
       "                                                                 5000],\n",
       "                                         'tfidfvectorizer__lowercase': [True,\n",
       "                                                                        False],\n",
       "                                         'tfidfvectorizer__max_df': [0.7, 0.75,\n",
       "                                                                     0.8, 0.85,\n",
       "                                                                     0.9, 1.0],\n",
       "                                         'tfidfvectorizer__min_df': [0.001,\n",
       "                                                                     0.01,\n",
       "                                                                     0.1],\n",
       "                                         'tfidfvectorizer__ngram_range': [(1,\n",
       "                                                                           1),\n",
       "                                                                          (1,\n",
       "                                                                           2),\n",
       "                                                                          (1,\n",
       "                                                                           3),\n",
       "                                                                          (1,\n",
       "                                                                           4)],\n",
       "                                         'tfidfvectorizer__norm': ['l1', 'l2'],\n",
       "                                         'tfidfvectorizer__tokenizer': [<function word_tokenize at 0x7fd5714a2160>]}],\n",
       "                   random_state=1, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs_pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "committed-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_pipe3_best = rs_pipe3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "frank-opinion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('tfidfvectorizer',\n",
      "                 TfidfVectorizer(lowercase=False, max_df=0.8, min_df=0.001,\n",
      "                                 ngram_range=(1, 3),\n",
      "                                 tokenizer=<function word_tokenize at 0x7fd5714a2160>)),\n",
      "                ('linearsvc', LinearSVC())],\n",
      "         verbose=True)\n"
     ]
    }
   ],
   "source": [
    "print(rs_pipe3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-movie",
   "metadata": {},
   "source": [
    "## 5. Stacked Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-jurisdiction",
   "metadata": {},
   "source": [
    "### 5.1. Stacked 1. Logistic Regression, Stochastic Gradient Descent, LinearSVC, TfidfVectorizer. \n",
    "<u>Input feature:</u> *text* column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eastern-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "private-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rs_pipe1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "accomplished-instrumentation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(rs_pipe2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "discrete-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rs_pipe3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "vocal-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_log_reg = TfidfVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                               norm=\"l2\", \n",
    "                               ngram_range=(1,1),\n",
    "                               min_df = 0.001, \n",
    "                               max_df = 0.8, \n",
    "                               lowercase=False)\n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", \n",
    "                             max_iter=2500, \n",
    "                             C = 1.0,\n",
    "                             random_state=1)\n",
    "#####\n",
    "\n",
    "tfidf_sgd = TfidfVectorizer(tokenizer = nltk__word_tokenizer, \n",
    "                            norm=\"l2\", \n",
    "                            ngram_range=(1,4), \n",
    "                            min_df = 0.1, \n",
    "                            max_df = 1.0, \n",
    "                            lowercase=True)\n",
    "sgd = SGDClassifier(penalty = \"l1\", \n",
    "                    max_iter = 1000, \n",
    "                    loss = \"hinge\", \n",
    "                    random_state=1)\n",
    "\n",
    "#####\n",
    "\n",
    "tfidf_linear_svc = TfidfVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                                  norm = \"l2\", \n",
    "                                  ngram_range=(1,3), \n",
    "                                  min_df = 0.001, \n",
    "                                  max_df = 0.8,\n",
    "                                  lowercase=False)\n",
    "linear_svc = LinearSVC(max_iter = 1000, \n",
    "                       C = 1.0,\n",
    "                       random_state=1)\n",
    "\n",
    "#####\n",
    "\n",
    "final_logreg = LogisticRegression(multi_class=\"multinomial\",\n",
    "                                 max_iter=1000)\n",
    "\n",
    "stacked1 = StackingClassifier(estimators=[('pipe1', make_pipeline(tfidf_log_reg, log_reg, verbose=True)),\n",
    "                                          ('pipe2', make_pipeline(tfidf_sgd, sgd, verbose=True)),\n",
    "                                          ('pipe3', make_pipeline(tfidf_linear_svc, linear_svc, verbose=True))],\n",
    "                              final_estimator=final_logreg,\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "weighted-multimedia",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  18.0s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.5s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  28.9s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.4s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  23.8s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   3.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  13.1s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.1s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  12.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  12.7s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   4.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  13.0s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  12.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.5min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  23.9s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  22.9s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  22.9s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  23.0s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  23.2s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.4min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  19.1s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  19.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  19.2s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  18.4s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  19.5s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('pipe1',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(lowercase=False,\n",
       "                                                                 max_df=0.8,\n",
       "                                                                 min_df=0.001,\n",
       "                                                                 tokenizer=<function word_tokenize at 0x7fd5714a2160>)),\n",
       "                                                ('logisticregression',\n",
       "                                                 LogisticRegression(max_iter=2500,\n",
       "                                                                    multi_class='ovr',\n",
       "                                                                    random_state=1))],\n",
       "                                         verbose=True)),\n",
       "                               ('pipe2',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(m...\n",
       "                                                 SGDClassifier(penalty='l1',\n",
       "                                                               random_state=1))],\n",
       "                                         verbose=True)),\n",
       "                               ('pipe3',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(lowercase=False,\n",
       "                                                                 max_df=0.8,\n",
       "                                                                 min_df=0.001,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              3),\n",
       "                                                                 tokenizer=<function word_tokenize at 0x7fd5714a2160>)),\n",
       "                                                ('linearsvc',\n",
       "                                                 LinearSVC(random_state=1))],\n",
       "                                         verbose=True))],\n",
       "                   final_estimator=LogisticRegression(max_iter=1000,\n",
       "                                                      multi_class='multinomial'),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "polar-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stacked1 = stacked1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "specified-energy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8290909090909091\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_stacked1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "charged-halloween",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.80      0.77      0.79       100\n",
      "         DEU       0.95      0.96      0.96       100\n",
      "         FRA       0.82      0.86      0.84       100\n",
      "         HIN       0.76      0.78      0.77       100\n",
      "         ITA       0.89      0.88      0.88       100\n",
      "         JPN       0.77      0.81      0.79       100\n",
      "         KOR       0.82      0.72      0.77       100\n",
      "         SPA       0.83      0.81      0.82       100\n",
      "         TEL       0.82      0.78      0.80       100\n",
      "         TUR       0.84      0.86      0.85       100\n",
      "         ZHO       0.82      0.89      0.86       100\n",
      "\n",
      "    accuracy                           0.83      1100\n",
      "   macro avg       0.83      0.83      0.83      1100\n",
      "weighted avg       0.83      0.83      0.83      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_stacked1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-darkness",
   "metadata": {},
   "source": [
    "### 5.2. Stacked 2. Logistic Regression, Stochastic Gradient Descent Classifier, LinearSVC, TfidfVectorizer <u>(BEST PERFORMING CLASSIFIER)</u>\n",
    "<u>Input feature:</u> lemmatized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "gentle-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_lemma = df.lemma_text.values\n",
    "y_lemma = df.Language.values\n",
    "\n",
    "X_train_lemma, X_dev_lemma, y_train_lemma, y_dev_lemma = train_test_split(X_lemma,\n",
    "                                                  y_lemma, \n",
    "                                                  test_size=0.1,\n",
    "                                                  random_state=1,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "lucky-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_log_reg = TfidfVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                               norm=\"l2\", \n",
    "                               ngram_range=(1,1),\n",
    "                               min_df = 0.001, \n",
    "                               max_df = 0.8, \n",
    "                               lowercase=False)\n",
    "log_reg = LogisticRegression(multi_class=\"ovr\", \n",
    "                             max_iter=2500, \n",
    "                             C = 1.0,\n",
    "                             random_state=1)\n",
    "#####\n",
    "\n",
    "tfidf_sgd = TfidfVectorizer(tokenizer = nltk__word_tokenizer, \n",
    "                            norm=\"l2\", \n",
    "                            ngram_range=(1,4), \n",
    "                            min_df = 0.1, \n",
    "                            max_df = 1.0, \n",
    "                            lowercase=True)\n",
    "sgd = SGDClassifier(penalty = \"l1\", \n",
    "                    max_iter = 1000, \n",
    "                    loss = \"hinge\", \n",
    "                    alpha = 0.0001,\n",
    "                    random_state=1)\n",
    "\n",
    "#####\n",
    "\n",
    "tfidf_linear_svc = TfidfVectorizer(tokenizer = nltk__word_tokenizer,\n",
    "                                  norm = \"l2\", \n",
    "                                  ngram_range=(1,3), \n",
    "                                  min_df = 0.001, \n",
    "                                  max_df = 0.8,\n",
    "                                  lowercase=False)\n",
    "linear_svc = LinearSVC(max_iter = 1000, \n",
    "                       C = 1.0,\n",
    "                       random_state=1)\n",
    "\n",
    "#####\n",
    "\n",
    "final_logreg = LogisticRegression(multi_class=\"multinomial\",\n",
    "                                 max_iter=1000)\n",
    "\n",
    "stacked2 = StackingClassifier(estimators=[('pipe1', make_pipeline(tfidf_log_reg, log_reg, verbose=True)),\n",
    "                                          ('pipe2', make_pipeline(tfidf_sgd, sgd, verbose=True)),\n",
    "                                          ('pipe3', make_pipeline(tfidf_linear_svc, linear_svc, verbose=True))],\n",
    "                              final_estimator=final_logreg,\n",
    "                              verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "sitting-sharing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  18.8s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  33.4s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  27.0s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  14.3s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   1.8s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  14.7s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.0s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  14.6s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   1.9s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  14.3s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  15.1s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.7min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  27.2s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  26.9s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  26.5s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.6s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  26.4s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.3s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  26.2s\n",
      "[Pipeline] ..... (step 2 of 2) Processing sgdclassifier, total=   1.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.8min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  21.5s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.3s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  20.9s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.4s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  21.3s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  20.7s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.2s\n",
      "[Pipeline] ... (step 1 of 2) Processing tfidfvectorizer, total=  21.2s\n",
      "[Pipeline] ......... (step 2 of 2) Processing linearsvc, total=   2.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('pipe1',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(lowercase=False,\n",
       "                                                                 max_df=0.8,\n",
       "                                                                 min_df=0.001,\n",
       "                                                                 tokenizer=<function word_tokenize at 0x7fae3987cf70>)),\n",
       "                                                ('logisticregression',\n",
       "                                                 LogisticRegression(max_iter=2500,\n",
       "                                                                    multi_class='ovr',\n",
       "                                                                    random_state=1))],\n",
       "                                         verbose=True)),\n",
       "                               ('pipe2',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(m...\n",
       "                                                 SGDClassifier(penalty='l1',\n",
       "                                                               random_state=1))],\n",
       "                                         verbose=True)),\n",
       "                               ('pipe3',\n",
       "                                Pipeline(steps=[('tfidfvectorizer',\n",
       "                                                 TfidfVectorizer(lowercase=False,\n",
       "                                                                 max_df=0.8,\n",
       "                                                                 min_df=0.001,\n",
       "                                                                 ngram_range=(1,\n",
       "                                                                              3),\n",
       "                                                                 tokenizer=<function word_tokenize at 0x7fae3987cf70>)),\n",
       "                                                ('linearsvc',\n",
       "                                                 LinearSVC(random_state=1))],\n",
       "                                         verbose=True))],\n",
       "                   final_estimator=LogisticRegression(max_iter=1000,\n",
       "                                                      multi_class='multinomial'),\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked2.fit(X_train_lemma, y_train_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "internal-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_stacked2 = stacked2.predict(X_dev_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dangerous-blowing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8336363636363636\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev_lemma, y_pred_stacked2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "better-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.82      0.79      0.81       100\n",
      "         DEU       0.90      0.93      0.92       100\n",
      "         FRA       0.81      0.87      0.84       100\n",
      "         HIN       0.80      0.77      0.79       100\n",
      "         ITA       0.89      0.90      0.90       100\n",
      "         JPN       0.83      0.80      0.82       100\n",
      "         KOR       0.80      0.77      0.79       100\n",
      "         SPA       0.84      0.77      0.80       100\n",
      "         TEL       0.82      0.83      0.83       100\n",
      "         TUR       0.84      0.86      0.85       100\n",
      "         ZHO       0.80      0.88      0.84       100\n",
      "\n",
      "    accuracy                           0.83      1100\n",
      "   macro avg       0.83      0.83      0.83      1100\n",
      "weighted avg       0.83      0.83      0.83      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev_lemma, y_pred_stacked2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "square-possibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(y_dev_lemma, y_pred_stacked2, rownames=['Actual'], colnames=['Predicted']) \n",
    "sn.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "choice-competition",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Combining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "matched-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "rational-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a development dataframe\n",
    "dev = df.groupby(\"Language\", group_keys=False).sample(n = 100, random_state=1)\n",
    "train = df.drop(dev.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cross-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900, 10) (1100, 10)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "contained-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZHO    900\n",
       "ITA    900\n",
       "DEU    900\n",
       "TUR    900\n",
       "TEL    900\n",
       "SPA    900\n",
       "FRA    900\n",
       "ARA    900\n",
       "HIN    900\n",
       "KOR    900\n",
       "JPN    900\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "breathing-cambridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ZHO    100\n",
       "KOR    100\n",
       "TUR    100\n",
       "SPA    100\n",
       "JPN    100\n",
       "ITA    100\n",
       "FRA    100\n",
       "DEU    100\n",
       "TEL    100\n",
       "ARA    100\n",
       "HIN    100\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.Language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrapped-lying",
   "metadata": {},
   "source": [
    "### 6.1. Text, text length in number of words, and character *n*-grams.\n",
    "- <u>Classifier:</u> Logistic Regression\n",
    "- <u>Input feature:</u> Text, text length in number of words, and character *n*-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "concrete-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"text\", \"n_words\"]]\n",
    "y_train = train[\"Language\"]\n",
    "\n",
    "X_dev = dev[[\"text\", \"n_words\"]]\n",
    "y_dev = dev[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "studied-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_text = TfidfVectorizer(ngram_range=(1,2),  # article Malmasi et al. (2018)\n",
    "                               min_df = 0.001, \n",
    "                               max_df = 0.8, \n",
    "                               lowercase=False)\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer=\"char_wb\",\n",
    "                            ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # for numeric feature, with_mean=False to work with sparse vector\n",
    "\n",
    "preprocessor1 = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (tfidf_text, \"text\"),\n",
    "    (tfidf_char, \"text\"),\n",
    "remainder=\"passthrough\")\n",
    "\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "molecular-hindu",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo1 = make_pipeline(preprocessor1, log_reg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "lesser-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  24.0s\n",
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total= 2.1min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('standardscaler',\n",
       "                                                  StandardScaler(with_mean=False),\n",
       "                                                  ['n_words']),\n",
       "                                                 ('tfidfvectorizer-1',\n",
       "                                                  TfidfVectorizer(lowercase=False,\n",
       "                                                                  max_df=0.8,\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  'text'),\n",
       "                                                 ('tfidfvectorizer-2',\n",
       "                                                  TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3)),\n",
       "                                                  'text')])),\n",
       "                ('logisticregression', LogisticRegression(max_iter=1000))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "plastic-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo1 = combo1.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "statistical-folder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7327272727272728\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_combo1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "addressed-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.71      0.72      0.72       100\n",
      "         DEU       0.74      0.93      0.83       100\n",
      "         FRA       0.78      0.77      0.77       100\n",
      "         HIN       0.63      0.67      0.65       100\n",
      "         ITA       0.84      0.78      0.81       100\n",
      "         JPN       0.70      0.68      0.69       100\n",
      "         KOR       0.65      0.70      0.67       100\n",
      "         SPA       0.74      0.62      0.67       100\n",
      "         TEL       0.69      0.76      0.72       100\n",
      "         TUR       0.83      0.74      0.78       100\n",
      "         ZHO       0.79      0.69      0.74       100\n",
      "\n",
      "    accuracy                           0.73      1100\n",
      "   macro avg       0.74      0.73      0.73      1100\n",
      "weighted avg       0.74      0.73      0.73      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-proceeding",
   "metadata": {},
   "source": [
    "### 6.2. Lemmatized text, function words and character *n*-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "annual-administrator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"lemma_text\", \"text\", \"stop_words\"]]\n",
    "y_train = train[\"Language\"]\n",
    "\n",
    "X_dev = dev[[\"lemma_text\", \"text\", \"stop_words\"]]\n",
    "y_dev = dev[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "perceived-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_lemma = TfidfVectorizer(ngram_range=(1,2),# article Malmasi et al. (2018)\n",
    "                              min_df=0.001,\n",
    "                              max_df = 0.8,\n",
    "                               lowercase=False)\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer=\"char_wb\",\n",
    "                            ngram_range=(1,3)) # article Malmasi et al. (2018), character uni-, bi- and trigrams\n",
    "\n",
    "tfidf_stop_words = TfidfVectorizer(ngram_range=(1,2)) # article Malmasi et al. (2018), function word uni- and bigrams.\n",
    "\n",
    "preprocessor2 = make_column_transformer(\n",
    "    (tfidf_lemma, \"lemma_text\"),\n",
    "    (tfidf_char, \"text\"),\n",
    "    (tfidf_stop_words, \"stop_words\")\n",
    ")\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, verbose=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "adverse-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo2 = make_pipeline(preprocessor2, logreg, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "decimal-vulnerability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] . (step 1 of 2) Processing columntransformer, total=  27.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 2 of 2) Processing logisticregression, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('tfidfvectorizer-1',\n",
       "                                                  TfidfVectorizer(lowercase=False,\n",
       "                                                                  max_df=0.8,\n",
       "                                                                  min_df=0.001,\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  'lemma_text'),\n",
       "                                                 ('tfidfvectorizer-2',\n",
       "                                                  TfidfVectorizer(analyzer='char_wb',\n",
       "                                                                  ngram_range=(1,\n",
       "                                                                               3)),\n",
       "                                                  'text'),\n",
       "                                                 ('tfidfvectorizer-3',\n",
       "                                                  TfidfVectorizer(ngram_range=(1,\n",
       "                                                                               2)),\n",
       "                                                  'stop_words')])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000, random_state=1, verbose=1))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combo2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "assumed-wayne",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo2 = combo2.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "accepted-number",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7045454545454546\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_combo2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "mechanical-anxiety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.64      0.66      0.65       100\n",
      "         DEU       0.75      0.89      0.82       100\n",
      "         FRA       0.71      0.72      0.71       100\n",
      "         HIN       0.66      0.73      0.70       100\n",
      "         ITA       0.78      0.76      0.77       100\n",
      "         JPN       0.71      0.66      0.68       100\n",
      "         KOR       0.61      0.67      0.64       100\n",
      "         SPA       0.75      0.63      0.68       100\n",
      "         TEL       0.72      0.76      0.74       100\n",
      "         TUR       0.77      0.61      0.68       100\n",
      "         ZHO       0.66      0.66      0.66       100\n",
      "\n",
      "    accuracy                           0.70      1100\n",
      "   macro avg       0.71      0.70      0.70      1100\n",
      "weighted avg       0.71      0.70      0.70      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-fortune",
   "metadata": {},
   "source": [
    "### 6.3. Lemmatized text, text length in number of words, and character *n*-grams\n",
    "- <u>Classifier:</u> best stacked classifier (obtaining 83%), with the best parameters for each of the classifiers (obtained during RandomizedSearchCV)\n",
    "    - Logistic Regression\n",
    "    - SGDClassifier\n",
    "    - LinearSVC\n",
    "- <u>Input features:</u> lemmatized text, text length in number of words, and character *n*-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eight-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[[\"text\", \"n_words\", \"lemma_text\"]]\n",
    "y_train = train[\"Language\"]\n",
    "\n",
    "X_dev = dev[[\"text\", \"n_words\", \"lemma_text\"]]\n",
    "y_dev = dev[\"Language\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "jewish-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_text = TfidfVectorizer(ngram_range=(1,2),  \n",
    "                               min_df = 0.001, \n",
    "                               max_df = 0.8, \n",
    "                               lowercase=False)\n",
    "\n",
    "tfidf_lemma = TfidfVectorizer(ngram_range=(1,2),  \n",
    "                              min_df = 0.001,\n",
    "                              max_df = 0.8,\n",
    "                              lowercase=False)\n",
    "\n",
    "tfidf_char = TfidfVectorizer(analyzer=\"char_wb\",\n",
    "                            ngram_range=(1,3))\n",
    "\n",
    "sc = StandardScaler(with_mean=False) # for numeric feature, with_mean=False to work with sparse vector\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (sc, [\"n_words\"]),\n",
    "    (tfidf_text, \"text\"),\n",
    "    (tfidf_char, \"text\"),\n",
    "    (tfidf_lemma, \"lemma_text\"),\n",
    "remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "periodic-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(multi_class=\"ovr\", \n",
    "                             max_iter=2500, \n",
    "                             C = 1.0,\n",
    "                             random_state=1, verbose=1)\n",
    "\n",
    "linear_svc = LinearSVC(max_iter = 1000, \n",
    "                       C = 1.0,\n",
    "                       random_state=1, verbose=1)\n",
    "\n",
    "sgd = SGDClassifier(penalty = \"l1\", \n",
    "                    max_iter = 1000, \n",
    "                    loss = \"hinge\", \n",
    "                    alpha = 0.0001,\n",
    "                    random_state=1, verbose=1)\n",
    "\n",
    "\n",
    "final_logreg = LogisticRegression(multi_class=\"multinomial\",\n",
    "                                 max_iter=1000)\n",
    "\n",
    "stacked = StackingClassifier(estimators=[('log_reg', log_reg),\n",
    "                                          ('sgd', sgd),\n",
    "                                          ('linear_svc', linear_svc)],\n",
    "                              final_estimator=final_logreg,\n",
    "                              verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "appointed-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo_stacked = make_pipeline(preprocessor, stacked, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "apart-expense",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##### This cell was commented after predicting, as it generated an enormously verbose output, which is very \n",
    "# unpractical for the Github Repo.\n",
    "\n",
    "#combo_stacked.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "stunning-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combo_stacked = combo_stacked.predict(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "surprising-ordinance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8145454545454546\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_dev, y_pred_combo_stacked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ancient-maintenance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.79      0.83      0.81       100\n",
      "         DEU       0.88      0.92      0.90       100\n",
      "         FRA       0.79      0.81      0.80       100\n",
      "         HIN       0.76      0.78      0.77       100\n",
      "         ITA       0.83      0.91      0.87       100\n",
      "         JPN       0.75      0.73      0.74       100\n",
      "         KOR       0.71      0.76      0.73       100\n",
      "         SPA       0.81      0.79      0.80       100\n",
      "         TEL       0.81      0.80      0.80       100\n",
      "         TUR       0.91      0.84      0.87       100\n",
      "         ZHO       0.92      0.79      0.85       100\n",
      "\n",
      "    accuracy                           0.81      1100\n",
      "   macro avg       0.82      0.81      0.81      1100\n",
      "weighted avg       0.82      0.81      0.81      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_dev, y_pred_combo_stacked))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
